{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ec38a8-c16e-4eed-b7e5-e91fb14ef1c0",
   "metadata": {},
   "source": [
    "Vision-language models\n",
    "===\n",
    "\n",
    "- SkyCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959cae13-cb4a-4b68-a81b-71b6a6b13633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527fc15-e722-487f-9f4f-538fdc188b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%env AWS_REQUEST_PAYER=requester\n",
    "%env AWS_ACCESS_KEY_ID=\n",
    "%env AWS_SECRET_ACCESS_KEY=\n",
    "%env AWS_SESSION_TOKEN="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84508ce0-3d3d-4a07-bf37-93dc60f42a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "from rastervision.pipeline.file_system.utils import json_to_file\n",
    "from rastervision.core.box import Box\n",
    "from rastervision.core.data import RasterioSource, Scene\n",
    "from rastervision.core.data.utils import geoms_to_geojson\n",
    "from rastervision.pytorch_learner.dataset import (\n",
    "    SemanticSegmentationSlidingWindowGeoDataset)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import albumentations as A\n",
    "from shapely.geometry import mapping\n",
    "import pystac_client\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39ebfe-4b6b-47c6-9cb2-33c6e1890661",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef7a11-83f1-4fac-8976-7930a28dca77",
   "metadata": {},
   "source": [
    "# Load SkyCLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17b663-7920-4065-a28e-af5a890f926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://raster-vision-ahassan/qe/SkyCLIP_ViT_L14_top50pct/epoch_20.pt SkyCLIP.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8d0a1-3c63-459c-8829-dfbfaef87011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model_name = 'ViT-L-14'\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e20a9-a366-4406-b7c1-2a148a42bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'SkyCLIP.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location=DEVICE)['state_dict']\n",
    "ckpt = {k[len('module.'):]:v for k, v in ckpt.items()}\n",
    "message = model.load_state_dict(ckpt)\n",
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aab304-95bb-4abc-838d-d65b055ca8df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1decbe3-2443-4c26-abc6-982423521596",
   "metadata": {},
   "source": [
    "# Get imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897b1bc-104b-4bf7-97ad-6a72f26c0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = Box(ymin=23.711, xmin=58.1, ymax=23.413, xmax=58.782)\n",
    "bbox_polygon = bbox.to_shapely().oriented_envelope\n",
    "search_geometry = mapping(bbox_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1712d93-41e4-40c6-ae05-15efae11ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open('https://earth-search.aws.element84.com/v1')\n",
    "\n",
    "items = catalog.search(\n",
    "    intersects=search_geometry,\n",
    "    datetime='2019-09-18',\n",
    "    collections=['naip'],\n",
    ").item_collection()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a245-56e7-4a0f-a7dc-792f66bece13",
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51504e47-83af-41b8-8189-170174ba9e3a",
   "metadata": {},
   "source": [
    "# Generate vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166c9bb-911b-49f7-8229-13e7d2a8a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_uris = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ed7b6-1e58-409b-9b0d-9954387dac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RasterioSource(uris=img_uris, channel_order=[0, 1, 2])\n",
    "rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd82c5-c505-4c3d-8469-6e72bee13e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.pytorch_learner import SemanticSegmentationSlidingWindowGeoDataset\n",
    "\n",
    "ds = SemanticSegmentationSlidingWindowGeoDataset.from_uris(\n",
    "    image_uri=image_uri,\n",
    "    image_raster_source_kw=dict(channel_order=[0, 1, 2]),\n",
    "    size=400,\n",
    "    stride=400,\n",
    "    out_size=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081a58-5646-4edc-8e8d-def8857b6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f186256-85ef-439c-afae-4d7b29f1faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this depends on the model architecture\n",
    "EMBEDDING_DIM_SIZE = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c159264-7ec2-4378-92cb-a8e949ae8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.zeros(len(ds), EMBEDDING_DIM_SIZE)\n",
    "\n",
    "with torch.inference_mode(), tqdm(dl, desc='Creating chip embeddings') as bar:\n",
    "    i = 0\n",
    "    for x, _ in bar:\n",
    "        x = x.to(DEVICE)\n",
    "        emb = model.encode_image(x)\n",
    "        embs[i:i + len(x)] = emb.cpu()\n",
    "        i += len(x)\n",
    "\n",
    "# normalize the embeddings\n",
    "embs /= embs.norm(dim=-1, keepdim=True)\n",
    "\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fb91b-f061-4608-9a7f-294e45d50f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_path = f'skysclip_naip_MA.pt'\n",
    "torch.save(embs, embs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61886a6-a522-403f-bdcc-8794c7d995f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp {embs_path} s3://..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb61ce0-cf68-4de1-9428-1d2836009bed",
   "metadata": {},
   "source": [
    "# Text-to-image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02276c-fc85-4c2e-bf10-a9093ef23195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chip_scores(text_queries, embs):\n",
    "    assert len(text_queries) == 1\n",
    "    text = tokenizer(text_queries)\n",
    "    with torch.inference_mode():\n",
    "        text_features = model.encode_text(text.to(DEVICE))\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features.cpu()\n",
    "        chip_scores = torch.cosine_similarity(text_features, embs)\n",
    "    return chip_scores\n",
    "\n",
    "def emb_idx_to_chip(i, windows, out_shape=(400, 400)):\n",
    "    chip, _ = ds[int(i)]\n",
    "    return chip\n",
    "\n",
    "def show_top_chips(chip_scores, windows_df, top_inds=None, nrows=5, ncols=5, figsize=(12, 12), w_pad=-2.5, h_pad=-2.5):\n",
    "    plt.close('all')\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    fig.tight_layout(w_pad=w_pad, h_pad=h_pad)\n",
    "    if top_inds is None:\n",
    "        top_inds = torch.topk(chip_scores, axs.size).indices\n",
    "    for ax, i in zip(tqdm(axs.flat), top_inds):\n",
    "        chip = emb_idx_to_chip(i, windows_df)\n",
    "        ax.imshow(chip)\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309304ad-f209-40fa-9246-37157d2b4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'house with swimming pool'\n",
    "\n",
    "chip_scores = get_chip_scores([text_query], embs)\n",
    "show_top_chips(chip_scores, ds.windows, nrows=2, ncols=4, figsize=(12, 6), w_pad=-(12/4), h_pad=-(6/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce618429-6e23-4cb2-bd79-29b61d73f004",
   "metadata": {},
   "source": [
    "# Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55084987-bef4-4b5b-b7f0-57a996b2016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_scores(text_queries, embs):\n",
    "    assert len(embs) == 1\n",
    "    text = tokenizer(text_queries)\n",
    "    with torch.inference_mode():\n",
    "        text_features = model.encode_text(text.to(DEVICE))\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features.cpu()\n",
    "        text_scores = torch.cosine_similarity(embs, text_features)\n",
    "    return text_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b720a-359f-47a5-bcb8-9ab0f46b19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = ds[123]\n",
    "img_emb = embs[[123]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80301713-872b-4fc5-a60a-292fcc50d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'warehouse',\n",
    "    'forest',\n",
    "    'harbor',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5733509e-5794-4c54-8fbc-a500d8c24890",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_scores = get_text_scores(classes, embs)\n",
    "text_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
