{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786d2d20-06c0-42f5-b201-0e3310b5197f",
   "metadata": {},
   "source": [
    "Run training jobs on the cloud\n",
    "===\n",
    "\n",
    "- RV pipeline\n",
    "- AWS SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d4d30-1b83-4b93-829a-390536bfc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from rastervision.pipeline.file_system.utils import (json_to_file, list_paths)\n",
    "from rastervision.core.data import (\n",
    "    ClassConfig, ClassInferenceTransformerConfig, DatasetConfig,\n",
    "    GeoJSONVectorSourceConfig, MultiRasterSourceConfig, RasterioSourceConfig,\n",
    "    RasterizedSourceConfig, RasterizerConfig, SceneConfig,\n",
    "    SemanticSegmentationLabelSourceConfig)\n",
    "from rastervision.core.rv_pipeline import (\n",
    "    SemanticSegmentationConfig, SemanticSegmentationPredictOptions,\n",
    "    WindowSamplingConfig, WindowSamplingMethod)\n",
    "from rastervision.pytorch_learner import (\n",
    "    ExternalModuleConfig, SemanticSegmentationGeoDataConfig,\n",
    "    SemanticSegmentationModelConfig, PlotOptions, SolverConfig)\n",
    "from rastervision.pytorch_backend import PyTorchSemanticSegmentationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d0c79-84e6-4ba2-b8ba-6875ac870892",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 's3://raster-vision-ahassan/un-sandstorm/data/gibs/img/VIIRS_SNPP_CorrectedReflectance_TrueColor/'\n",
    "m11_i2_i1_dir = 's3://raster-vision-ahassan/un-sandstorm/data/gibs/img/VIIRS_SNPP_CorrectedReflectance_BandsM11-I2-I1/'\n",
    "m3_i3_dir = 's3://raster-vision-ahassan/un-sandstorm/data/gibs/img/VIIRS_SNPP_CorrectedReflectance_BandsM3-I3-M11/'\n",
    "label_dir = 's3://raster-vision-ahassan/un-sandstorm/data/gibs/labels_geojson/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3906c55-a2f9-44a5-8025-d5a5d029ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_config = ClassConfig(\n",
    "    names=['background', 'dust'],\n",
    "    colors=['lightgray', 'maroon'],\n",
    "    null_class='background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba14e9-437e-4ae0-aeed-f36641ec499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_uris = sorted(list_paths(img_dir, ext='.tif'))\n",
    "len(img_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dac4bb-ed59-4107-b522-b309f590fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "m11_i2_i1_uris = [\n",
    "    join(m11_i2_i1_dir, f'{Path(uri).stem}.tif') for uri in img_uris\n",
    "]\n",
    "m3_i3_uris = [join(m3_i3_dir, f'{Path(uri).stem}.tif') for uri in img_uris]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d1eb5-fb82-4a22-b418-a483d4eebe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_uris = [join(label_dir, f'{Path(uri).stem}.json') for uri in img_uris]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857c61e-9929-44ab-8740-db5ed68eb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scene(img_uri: str,\n",
    "               label_uri: str,\n",
    "               class_config: ClassConfig,\n",
    "               extra_raster_uris: list[str] | None = None):\n",
    "    if extra_raster_uris is None:\n",
    "        raster_source = RasterioSourceConfig(uris=img_uri)\n",
    "    else:\n",
    "        raster_uris = [img_uri] + extra_raster_uris\n",
    "        raster_sources = [\n",
    "            RasterioSourceConfig(uris=uri) for uri in raster_uris\n",
    "        ]\n",
    "        raster_source = MultiRasterSourceConfig(raster_sources=raster_sources)\n",
    "    label_vector_source = GeoJSONVectorSourceConfig(\n",
    "        uris=label_uri,\n",
    "        transformers=[\n",
    "            ClassInferenceTransformerConfig(\n",
    "                default_class_id=class_config.get_class_id('background'),\n",
    "                class_name_mapping=dict(\n",
    "                    dust_over_land='dust', dust_over_water='dust'),\n",
    "            )\n",
    "        ])\n",
    "    label_raster_source = RasterizedSourceConfig(\n",
    "        vector_source=label_vector_source,\n",
    "        rasterizer_config=RasterizerConfig(\n",
    "            background_class_id=class_config.get_class_id('background'),\n",
    "            all_touched=True,\n",
    "        ))\n",
    "    label_source = SemanticSegmentationLabelSourceConfig(\n",
    "        raster_source=label_raster_source)\n",
    "    scene = SceneConfig(\n",
    "        id=Path(img_uri).stem,\n",
    "        raster_source=raster_source,\n",
    "        label_source=label_source,\n",
    "    )\n",
    "    return scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697deb3-f4a3-4c3f-80f3-906e5cc03c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [\n",
    "    make_scene(\n",
    "        img_uri,\n",
    "        label_uri,\n",
    "        class_config,\n",
    "        extra_raster_uris=[m11_i2_i1_uri, m3_i3_uri])\n",
    "    for img_uri, label_uri, m11_i2_i1_uri, m3_i3_uri in zip(\n",
    "        img_uris, label_uris, m11_i2_i1_uris, m3_i3_uris)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192c2d4-93b3-40eb-a95e-d02f3937afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transform = A.Compose([\n",
    "    A.Flip(),\n",
    "    A.ShiftScaleRotate(),\n",
    "])\n",
    "\n",
    "\n",
    "def make_pipeline(out_uri: str, scene_dataset: 'DatasetConfig',\n",
    "                  class_config: 'ClassConfig', chip_sz: int, img_sz: int,\n",
    "                  num_channels: int, channel_display_groups: dict,\n",
    "                  solver: 'SolverConfig'):\n",
    "\n",
    "    window_sampling_opts = {}\n",
    "    # set window configs for training scenes\n",
    "    for s in scene_dataset.train_scenes:\n",
    "        window_sampling_opts[s.id] = WindowSamplingConfig(\n",
    "            method=WindowSamplingMethod.random,\n",
    "            size_lims=(chip_sz, chip_sz + 1),\n",
    "            size=img_sz,\n",
    "            max_windows=16,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "    # set window configs for validation scenes\n",
    "    for s in scene_dataset.validation_scenes:\n",
    "        window_sampling_opts[s.id] = WindowSamplingConfig(\n",
    "            method=WindowSamplingMethod.sliding,\n",
    "            size=chip_sz,\n",
    "            stride=(chip_sz // 2))\n",
    "\n",
    "    data = SemanticSegmentationGeoDataConfig(\n",
    "        scene_dataset=scene_dataset,\n",
    "        sampling=window_sampling_opts,\n",
    "        img_sz=img_sz,\n",
    "        img_channels=num_channels,\n",
    "        num_workers=4,\n",
    "        aug_transform=A.to_dict(aug_transform),\n",
    "        plot_options=PlotOptions(\n",
    "            channel_display_groups=channel_display_groups))\n",
    "\n",
    "    model = SemanticSegmentationModelConfig(\n",
    "        external_def=ExternalModuleConfig(\n",
    "            github_repo='AdeelH/pytorch-fpn:0.3',\n",
    "            name='fpn',\n",
    "            entrypoint='make_fpn_resnet',\n",
    "            entrypoint_kwargs={\n",
    "                'name': 'resnet18',\n",
    "                'fpn_type': 'panoptic',\n",
    "                'num_classes': len(class_config),\n",
    "                'fpn_channels': 128,\n",
    "                'in_channels': num_channels,\n",
    "                'out_size': (img_sz, img_sz),\n",
    "            }))\n",
    "\n",
    "    backend = PyTorchSemanticSegmentationConfig(\n",
    "        data=data,\n",
    "        model=model,\n",
    "        solver=solver,\n",
    "        log_tensorboard=False,\n",
    "        run_tensorboard=False,\n",
    "    )\n",
    "\n",
    "    predict_options = SemanticSegmentationPredictOptions(chip_sz=chip_sz)\n",
    "\n",
    "    pipeline = SemanticSegmentationConfig(\n",
    "        root_uri=out_uri,\n",
    "        dataset=scene_dataset,\n",
    "        backend=backend,\n",
    "        predict_options=predict_options)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dce952-7423-4a09-a686-f45ad60c9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir = 's3://raster-vision-ahassan/un-sandstorm/out/2022-04-26_train_cv_w2_m11i2i1'\n",
    "out_dir = 's3://raster-vision-ahassan/un-sandstorm/out/2022-04-26_train_cv_w2_m11i2i1_m3i3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425d1d2-536f-424d-a18e-eb0350eabebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2)\n",
    "\n",
    "split_pipelines = [None] * 2\n",
    "for split_num, (train_inds, val_inds) in enumerate(kf.split(img_uris)):\n",
    "    scene_dataset = DatasetConfig(\n",
    "        class_config=class_config,\n",
    "        train_scenes=[scenes[i] for i in train_inds],\n",
    "        validation_scenes=[scenes[i] for i in val_inds],\n",
    "    )\n",
    "    split_out_dir = join(out_dir, f'split-{split_num}')\n",
    "    split_pipelines[split_num] = make_pipeline(\n",
    "        out_uri=split_out_dir,\n",
    "        scene_dataset=scene_dataset,\n",
    "        class_config=class_config,\n",
    "        chip_sz=512,\n",
    "        img_sz=256,\n",
    "        num_channels=8,\n",
    "        channel_display_groups={\n",
    "            'RGB': [0, 1, 2],\n",
    "            'M11-I2-I1': [3, 4, 5],\n",
    "            'M3-I3': [6, 7]\n",
    "        },\n",
    "        solver=SolverConfig(batch_sz=16, lr=1e-4),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546ed62-9a9b-4185-b053-e2f880569c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_json_path = join('data', 'train', Path(out_dir).stem, 'configs.json')\n",
    "pipelines_json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9af90-5aac-431e-b680-1e5582015cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_file([p.dict() for p in split_pipelines], pipelines_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c185f5-df40-4433-bdc7-52694b4d76f0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7018e-2512-4084-aeb6-84fea25bb7b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rastervision run sagemaker {pipelines_json_path} train --pipeline-run-name \"cv-w2-m11i2i1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe6d05-a30f-45e4-8dc1-1285aef4a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker list-training-jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e6f67-a19c-421b-ace4-28cc6ad76e2e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
